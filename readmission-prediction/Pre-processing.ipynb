{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_options = {\"SUBSAMPLE\": 0, \"SMOTE\": 1, \"UNDER\": 3, \"OVER\": 4, \"UNDER_OVER\": 5, \"NONE\": 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_data_path = \"/home/littlefield/mimic-data/mimiciii/1.4/\"\n",
    "def get_mimic_dataset(table_name):\n",
    "    try:\n",
    "        file = table_name + \".csv\"\n",
    "        return pd.read_csv(mimic_data_path + file, low_memory=False)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Unable to load data table\", table_name, \"from\", mimic_data_path + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = get_mimic_dataset(\"NOTEEVENTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = get_mimic_dataset(\"ADMISSIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions.ADMITTIME = pd.to_datetime(admissions.ADMITTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "admissions.DISCHTIME = pd.to_datetime(admissions.DISCHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')\n",
    "admissions.DEATHTIME = pd.to_datetime(admissions.DEATHTIME, format = '%Y-%m-%d %H:%M:%S', errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find Next Unplanned Admission Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by subject_ID and admission date\n",
    "admissions = admissions.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "admissions = admissions.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the next admission date and type for each subject using groupby\n",
    "# you have to use groupby otherwise the dates will be from different subjects\n",
    "admissions['NEXT_ADMITTIME'] = admissions.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
    "\n",
    "# get the next admission type\n",
    "admissions['NEXT_ADMISSION_TYPE'] = admissions.groupby('SUBJECT_ID').ADMISSION_TYPE.shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Out Elective Admissions and Back Fill NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows where next admission is elective and replace with naT or nan\n",
    "rows = admissions.NEXT_ADMISSION_TYPE == 'ELECTIVE'\n",
    "admissions.loc[rows,'NEXT_ADMITTIME'] = pd.NaT\n",
    "admissions.loc[rows,'NEXT_ADMISSION_TYPE'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by subject_ID and admission date\n",
    "# it is safer to sort right before the fill in case something changed the order above\n",
    "admissions = admissions.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "# back fill (this will take a little while)\n",
    "admissions[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']] = admissions.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']].fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Number of Days till Next Admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions['DAYS_NEXT_ADMIT'] =  (admissions.NEXT_ADMITTIME - admissions.DISCHTIME).dt.total_seconds()/(24*60*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter to Use Discharge Notes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_dis = notes.loc[notes.CATEGORY == 'Discharge summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_dis_last = (notes_dis.groupby(['SUBJECT_ID','HADM_ID']).nth(-1)).reset_index()\n",
    "assert notes_dis_last.duplicated(['HADM_ID']).sum() == 0, 'Multiple discharge summaries per admission'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge ADMISSIONS and NOTEEVENTS Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_notes = pd.merge(admissions[['SUBJECT_ID','HADM_ID','ADMITTIME','DISCHTIME','DAYS_NEXT_ADMIT','NEXT_ADMITTIME','ADMISSION_TYPE','DEATHTIME']],\n",
    "                        notes_dis_last[['SUBJECT_ID','HADM_ID','TEXT']], \n",
    "                        on = ['SUBJECT_ID','HADM_ID'],\n",
    "                        how = 'left')\n",
    "assert len(admissions) == len(adm_notes), 'Number of rows increased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Amount of Admissions Missing Discharge Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_notes.TEXT.isnull().sum() / len(adm_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_notes.groupby('ADMISSION_TYPE').apply(lambda g: g.TEXT.isnull().sum())/adm_notes.groupby('ADMISSION_TYPE').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_notes_clean = adm_notes.loc[adm_notes.ADMISSION_TYPE != 'NEWBORN'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Output Label: Patients who are readmitted within 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_notes_clean['OUTPUT_LABEL'] = (adm_notes_clean.DAYS_NEXT_ADMIT < 30).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of positive samples:', (adm_notes_clean.OUTPUT_LABEL == 1).sum())\n",
    "print('Number of negative samples:',  (adm_notes_clean.OUTPUT_LABEL == 0).sum())\n",
    "print('Total samples:', len(adm_notes_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Training/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_notes_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle the samples\n",
    "adm_notes_clean = adm_notes_clean.sample(n = len(adm_notes_clean), random_state = 42)\n",
    "adm_notes_clean = adm_notes_clean.reset_index(drop = True)\n",
    "\n",
    "adm_notes_clean = adm_notes_clean[adm_notes_clean.DEATHTIME.isnull()]\n",
    "\n",
    "# Save 30% of the data as validation and test data \n",
    "valid_test=adm_notes_clean.sample(frac=0.30,random_state=42)\n",
    "\n",
    "test = valid_test.sample(frac = 0.5, random_state = 42)\n",
    "valid = valid_test.drop(test.index)\n",
    "\n",
    "# use the rest of the data as training data\n",
    "train = adm_notes_clean.drop(valid_test.index)\n",
    "\n",
    "print('Test prevalence(n = %d):'%len(test), test.OUTPUT_LABEL.sum()/ len(test))\n",
    "print('Valid prevalence(n = %d):'%len(valid), valid.OUTPUT_LABEL.sum()/ len(valid))\n",
    "print('Train all prevalence(n = %d):'%len(train), train.OUTPUT_LABEL.sum()/ len(train))\n",
    "print('all samples (n = %d)'%len(adm_notes_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_imbalance(train, method=\"SUBSAMPLE\"):\n",
    "    if method == \"SUBSAMPLE\":\n",
    "        subsample(train)\n",
    "    elif(method == \"SMOTE\"):\n",
    "        smote(train)\n",
    "    elif(method == \"UNDER\"):\n",
    "        undersample(train)\n",
    "    elif(method == \"OVER\"):\n",
    "        oversample(train)\n",
    "    else:\n",
    "        under_over_sample(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(train, pos_class=1, random_state=42):\n",
    "    # split the training data into positive and negative\n",
    "    rows_pos = train.OUTPUT_LABEL == pos_class\n",
    "    train_pos = train.loc[rows_pos]\n",
    "    train_neg = train.loc[~rows_pos]\n",
    "\n",
    "    # merge the balanced data\n",
    "    whole_df = pd.concat([train_pos, train_neg.sample(n = len(train_pos), random_state = random_state)],axis = 0)\n",
    "\n",
    "    # shuffle the order of training samples \n",
    "    train_sub = whole_df.sample(n = len(whole_df), random_state = random_state).reset_index(drop = True)\n",
    "    \n",
    "    return train_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def undersample(X, y, samp_rate=0.5, random_state=42):\n",
    "    rus = RandomUnderSampler(random_state=42, sampling_strategy=samp_rate)\n",
    "    X_res, y_res = rus.fit_resample(np.array(X).reshape(-1, 1), y)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(X, y, samp_rate=0.5, random_state=42):\n",
    "    ros = RandomOverSampler(random_state=42, sampling_strategy=samp_rate)\n",
    "    X_res, y_res = ros.fit_resample(np.array(X).reshape(-1, 1), y)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def under_over_sample(X, y, under_samp_rate=0.15, over_samp_rate=0.75, random_state=42):\n",
    "    under = RandomUnderSampler(sampling_strategy=under_samp_rate, random_state=random_state, )\n",
    "    over = RandomOverSampler(sampling_strategy=over_samp_rate, random_state=random_state)\n",
    "    steps = [('under', under), ('over', over)]\n",
    "    pipeline = Pipeline(steps = steps)\n",
    "    \n",
    "    X_res, y_res = pipeline.fit_resample(np.array(X).reshape(-1, 1), y)\n",
    "    \n",
    "    combined = pd.DataFrame( data = {\"TEXT\": X_res.squeeze(), \"OUTPUT_LABEL\": y_res})\n",
    "    \n",
    "    return combined.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampled = under_over_sample(train.TEXT, train.OUTPUT_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(train_sampled.OUTPUT_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prevalence is low, subsample negatives in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train prevalence (n = %d):'%len(data), data.OUTPUT_LABEL.sum()/ len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Notes: Remove new lines and carriage returns, and replace NaNs with '   '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    df.TEXT = df.TEXT.fillna(' ')\n",
    "    df.TEXT = df.TEXT.str.replace('\\n',' ')\n",
    "    df.TEXT = df.TEXT.str.replace('\\r',' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampled = preprocess_text(train_sampled)\n",
    "valid = preprocess_text(valid)\n",
    "test = preprocess_text(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save training, valid, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = \"/home/littlefield/MIMIC-NLP/readmission-prediction/data/\"\n",
    "if not os.path.exists(data_pth):\n",
    "    os.mkdir(data_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clinical_note_utils import extract_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_notes(data_pth, \"train\", train_sub[train_sub.OUTPUT_LABEL == 0], ds_type=\"train\", label=\"neg\")\n",
    "# extract_notes(data_pth, \"train\", train_sub[train_sub.OUTPUT_LABEL == 1], ds_type=\"train\", label=\"pos\")\n",
    "# extract_notes(data_pth, \"valid\", valid[valid.OUTPUT_LABEL == 0], ds_type=\"valid\", label=\"neg\")\n",
    "# extract_notes(data_pth, \"valid\", valid[valid.OUTPUT_LABEL == 1], ds_type=\"valid\", label=\"pos\")\n",
    "# extract_notes(data_pth, \"test\", test[test.OUTPUT_LABEL == 0], ds_type=\"test\", label=\"neg\")\n",
    "# extract_notes(data_pth, \"test\", test[test.OUTPUT_LABEL == 1], ds_type=\"test\", label=\"pos\")\n",
    "# extract_notes(data_pth, \"unsup\", not_used, ds_type=\"unsup\", label=\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampled[[\"TEXT\", \"OUTPUT_LABEL\"]].to_csv(data_pth + \"train_under-oversampled.csv\", index=False)\n",
    "valid[[\"TEXT\", \"OUTPUT_LABEL\"]].to_csv(data_pth + \"valid.csv\", index=False)\n",
    "test[[\"TEXT\", \"OUTPUT_LABEL\"]].to_csv(data_pth + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
