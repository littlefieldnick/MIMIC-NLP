{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "\n",
    "from clinical_note_utils import *\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_roc = []\n",
    "test_roc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/littlefield/MIMIC-NLP/readmission-prediction/\"\n",
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastAiBertTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around BertTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, tokenizer: BertTokenizer, max_seq_len: int=128, **kwargs):\n",
    "        self._pretrained_tokenizer = tokenizer\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length\"\"\"\n",
    "        return [\"[CLS]\"] + self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2] + [\"[SEP]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_data = load_data(path, 'data/bert-clinical.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_bert = BertForSequenceClassification.from_pretrained(\"emilyalsentzer/Bio_Discharge_Summary_BERT\",\n",
    "              num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "  \n",
    "    def __init__(self, transformer_model: BertForSequenceClassification, include_act=False, act_func=None):\n",
    "        super(CustomTransformerModel,self).__init__()\n",
    "        self.include_act = include_act\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "        if include_act:\n",
    "            self.act = act_func\n",
    "   \n",
    "    def forward(self, x):\n",
    "        # Return only the logits from the transfomer\n",
    "        logits = self.transformer(x)[0] \n",
    "        \n",
    "        if self.include_act:\n",
    "            return self.act(logits)\n",
    "        \n",
    "        return logits.reshape(-1)\n",
    "\n",
    "model = CustomTransformerModel(clinical_bert, include_act=True, act_func=nn.Sigmoid())\n",
    "\n",
    "from fastai.callbacks import *\n",
    "\n",
    "learn = Learner(clinical_data, model, loss_func=nn.CrossEntropyLoss(), metrics=[AUROC(), Precision(), Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"clinical-bert-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.get_preds(ds_type=DatasetType.Valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(inp, preds, ds=\"Validation\", thresh=None):\n",
    "    best_thresh = thresh\n",
    "    if thresh is None:\n",
    "        print(\"Theshold is not provided, calculating...\")\n",
    "        best_thresh = J_statistic(inp, preds)\n",
    "    final_preds = np.array([1 if p > best_thresh else 0 for p in preds])\n",
    "    acc = pos_accuracy(learn.data.valid_ds.y.items, final_preds, thresh=best_thresh)\n",
    "    auc_score = auc(inp, preds)\n",
    "    f1, precision, recall = f1_precision_recall(inp, final_preds)\n",
    "    \n",
    "    print(\"================================\", ds, \"Metrics for Postive Class ================================\")\n",
    "    print(\"Best Threshold:\", best_thresh)\n",
    "    print(\"Positive Class Acc.:\", acc)\n",
    "    print(\"AUC:\", auc_score)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    \n",
    "    scores = {\"best_thresh\": best_thresh,\n",
    "              \"acc\": acc,\n",
    "              \"auc\": auc_score,\n",
    "              \"f1\": f1, \n",
    "              \"precision\": precision,\n",
    "              \"recall\": recall}\n",
    "    \n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_metrics_1 = eval_model(learn.data.valid_ds.y.items, preds[0][:, 1])\n",
    "valid_roc.append(valid_metrics_1[\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "learn.data.add_test(test)\n",
    "t_preds = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics_1 = eval_model(test.OUTPUT_LABEL, t_preds[0][:, 1], ds=\"Test\", thresh=valid_metrics_1[\"best_thresh\"])\n",
    "test_roc.append(test_metrics_1[\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"clinical-bert-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.get_preds(ds_type=DatasetType.Valid)\n",
    "valid_metrics_2 = eval_model(learn.data.valid_ds.y.items, preds[0][:, 1])\n",
    "valid_roc.append(valid_metrics_2[\"auc\"])\n",
    "\n",
    "test_metrics_2 = eval_model(test.OUTPUT_LABEL, t_preds[0][:, 1], ds=\"Test\", thresh=valid_metrics_2[\"best_thresh\"])\n",
    "test_roc.append(test_metrics_2[\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"clinical-bert-3\")\n",
    "\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid)\n",
    "valid_metrics_3 = eval_model(learn.data.valid_ds.y.items, preds[0][:, 1])\n",
    "valid_roc.append(valid_metrics_3[\"auc\"])\n",
    "\n",
    "test_metrics_3 = eval_model(test.OUTPUT_LABEL, t_preds[0][:, 1], ds=\"Test\", thresh=valid_metrics_3[\"best_thresh\"])\n",
    "test_roc.append(test_metrics_3[\"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"clinical-bert-unfrozen-1\")\n",
    "\n",
    "preds = learn.get_preds(ds_type=DatasetType.Valid)\n",
    "valid_metrics_4 = eval_model(learn.data.valid_ds.y.items, preds[0][:, 1])\n",
    "valid_roc.append(valid_metrics_4[\"auc\"])\n",
    "\n",
    "test_metrics_4 = eval_model(test.OUTPUT_LABEL, t_preds[0][:, 1], ds=\"Test\", thresh=valid_metrics_4[\"best_thresh\"])\n",
    "test_roc.append(test_metrics_4[\"auc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
